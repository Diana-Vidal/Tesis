View(def_zona)
View(regres_zona)
# Agrupamos por zona
def_zona <- def_zmvm %>%
group_by(FECHA_DEF, ZONA) %>%
summarise(num_def = n())%>%
rename(fecha = FECHA_DEF,
zona = ZONA)
def_zona_2 <- def_zmvm %>%
group_by(FECHA_DEF, SEXO, GRUPO_EDAD, DIABETES, EPOC, ASMA, HIPERTENSION, CARDIOVASCULAR,RENAL_CRONICA, ZONA) %>%
summarise(num_def = n())%>%
rename(fecha = FECHA_DEF,
zona = ZONA)
# Cargamos las bases de los promedios de PM2.5 de 2019 a 2021
pm2019 <- fread("Bases/Bases PM/promedios_2019_ps.csv")
pm2020 <- fread("Bases/Bases PM/promedios_2020_ps.csv")
pm2021 <- fread("Bases/Bases PM/promedios_2021_ps.csv")
#Cargamos el catalogo de estaciones
cat_est <- fread("Bases/Bases PM/Catálogos/cat_estacion.csv")
# Cargamos base de estaciones con municipio
estac_mpo <- fread("Bases/Bases PM/Catálogos/estac_mpo.csv")
# Unimos las bases de los tres años
# Unimos con catalogo de estaciones
# Unimos con los municipios donde se encuentran las estaciones
pm <- rbind(pm2019,pm2020, pm2021) %>%
left_join(., cat_est, by = c("id_station" = "cve_estac")) %>%
left_join(.,estac_mpo, by = c("nom_estac" = "Nombre")) %>%
left_join(., zonas, by = c("Alcaldía o municipio" = "MUNICIPIO",
"Entidad" = "ENTIDAD")) %>%
rename("fecha" = 1,
"cve_estac" = 2,
"parametro" = 3,
"municipio" = 13,
"entidad" =14,
"zona" = 15) %>%
mutate(fecha = as.Date(fecha, format = "%Y-%m-%d"),
parametro = trimws(parametro, "r")) %>%
select(fecha, cve_estac, nom_estac, value, parametro, longitud, latitud, municipio, entidad, zona)
# Agrupamos por zona
prom_pm_zona <- pm %>%
drop_na(zona) %>%
group_by(fecha, parametro, zona) %>%
summarise(value= mean(value))
# Cargamos base de pm
pm <- fread("Bases/pm.csv",
encoding = "Latin-1")
# Agrupamos por zona
prom_pm_zona <- pm %>%
drop_na(zona) %>%
group_by(fecha, parametro, zona) %>%
summarise(value= mean(value))
library(data.table)
library(tidyverse)
library(dint)
library(lubridate)
library(naniar)
# Cargamos las bases de los datos meteorologicos de 2019 a 2021
meteo2019 <- fread("Bases/Bases Meteo/meteorología_2019.CSV") %>%
select(Fecha = date,
Estacion = id_station,
Parametro = id_parameter,
Valor = value,
Unidad = unit) %>%
mutate(Fecha = dmy_hm(Fecha))
meteo2020 <- fread("Bases/Bases Meteo/meteorología_2020.CSV") %>%
select(Fecha = date,
Estacion = id_station,
Parametro = id_parameter,
Valor = value,
Unidad = unit) %>%
mutate(Fecha = dmy_hm(Fecha))
meteo2021 <- fread("Bases/Bases Meteo/meteorología_2021.CSV") %>%
select(Fecha = date,
Estacion = id_station,
Parametro = id_parameter,
Valor = value,
Unidad = unit) %>%
mutate(Fecha = dmy_hm(Fecha))
# Cargamos base de zonas
zonas <- fread("Bases/Zonas_ZMVM.csv")
# Cargamos catalogo de estaciones
cat_estac_meteo <- fread("Bases/Bases Meteo/Catálogos/cat_estac_meteo.csv",
encoding = "Latin-1")
# Unimos las bases de los tres años
# Unimos con catalogo de estaciones
# Unimos con los municipios donde se encuentran las estaciones
# Renombramos las columnas y las acomodammos
# Filtramos los parametros que vamos a utilizar
meteo <- rbind(meteo2019,meteo2020, meteo2021) %>%
left_join(., cat_estac_meteo, by = c("Estacion" = "cve_estac")) %>%
left_join(., zonas, by = c("Alcaldía o municipio" = "MUNICIPIO",
"Entidad" = "ENTIDAD")) %>%
rename("fecha" = 1,
"id_station" = 2,
"parametro" = 3,
"value" = 4,
"nom_estac" = 6,
"municipio" = 9,
"entidad" =10,
"zona" = 11) %>%
# mutate(fecha = as.Date(fecha, format = "%Y-%m-%d")) %>%
select(fecha,nom_estac, value, parametro, municipio, entidad, zona) %>%
filter(parametro%in%c("RH", "TMP", "WSP")) %>%
drop_na(zona)
# Revisamos las estaciones que cumplen con más de 18 mediciones en 24 h
# Quitamos valores nulos
# Cambiamos a formato fecha, separamos las horasa y ajustamos la fecha para las 12 h
# Agrupamos por dia, nombre de estacion y parametro y agrupamos por el numero de horas
promedios_meteo <- meteo %>%
drop_na(value) %>%
# mutate(nom_estac = recode(nom_estac, "AJUSCO" = "AJUSCO-MEDIO",
#                           "AJUSCO MEDIO" = "AJUSCO-MEDIO",
#                           "SANTA FE" = "CUAJIMALPA",
#                           "SAN AGUSTIN" = "AGUS-XAL",
#                           "XALOSTOC" = "AGUS-XAL",
#                           "GUSTAVO A. MADERO" = "GAM-LAA",
#                           "LABORATORIO DE ANALISIS AMBIENTAL" = "GAM-LAA",
#                           "UAM IZTAPALAPA" = "UAMIZTA-SANTIAGO",
#                           "SANTIAGO ACAHUALTEPEC" = "UAMIZTA-SANTIAGO",
#                           "NEZAHUALCOYOTL" = "NEZA-FES",
#                           "FES ARAGON" = "NEZA-FES")) %>%
mutate(dia = as.Date(fecha, format = "%Y-%m-%d"),
hora = hms::hms(second(fecha), minute(fecha), hour(fecha)),
dia2 = if_else(hora == 00:00:00,as.Date((dia)-1), dia)) %>%
# filter(nom_estac == "UAM XOCHIMILCO") %>%
select(dia2, hora, nom_estac, value, parametro) %>%
group_by(dia2, nom_estac, parametro) %>%
summarise(numhoras = n()) %>%
mutate(pasa = if_else(numhoras>= 18, "pasa", "no pasa"))
# Revisamos cuantas estaciones pasan
prop.table(table(promedios_meteo$pasa))
# Revisamos el numero de horas
summary(promedios_meteo$numhoras)
# Promedios de las estaciones
# Quitamos valores nulos
# Cambiamos a formato fecha, separamos las horasa y ajustamos la fecha para las 12 h
# Agrupamos por fecha, nombre de estacion, parametros, municipio, entidad y zona
# Calculamos el promedio
prom_meteo <- meteo %>%
drop_na(value) %>%
mutate(dia = as.Date(fecha, format = "%Y-%m-%d"),
hora = hms::hms(second(fecha), minute(fecha), hour(fecha)),
dia2 = if_else(hora == 00:00:00,as.Date((dia)-1), dia)) %>%
group_by(dia2, nom_estac, parametro, municipio, entidad, zona) %>%
summarise(value = mean(value, na.rm = T)) %>%
rename(fecha = dia2) %>%
select(fecha, nom_estac, value, parametro, municipio, entidad, zona)
# Unimos base de promedios con la de promedios pasa
meteo_promedios <- left_join(prom_meteo, promedios_meteo, by = c("fecha" = "dia2",
"nom_estac",
"parametro")) %>%
filter(pasa == "pasa")
# Revismos que solo esten lo valores que si cumplen con criterio de representatividad
prop.table(table(meteo_promedios$pasa))
unique(meteo_promedios$pasa)
# Agrupamos por zona
prom_meteo_zona <- meteo_promedios %>%
group_by(fecha, parametro, zona) %>%
summarise(value= mean(value))
# Union de bases de pm y meteo para regresion
regresion_zona <- merge(prom_pm_zona, prom_meteo_zona, all = T)
def_zmvm <- fread("Bases/def_zmvm.csv",
encoding = "Latin-1")
def_zona_2 <- def_zmvm %>%
group_by(FECHA_DEF, SEXO, GRUPO_EDAD, DIABETES, EPOC, ASMA, HIPERTENSION, CARDIOVASCULAR,RENAL_CRONICA, ZONA) %>%
summarise(num_def = n())%>%
rename(fecha = FECHA_DEF,
zona = ZONA)
def_zona_2 <- def_zmvm %>%
group_by(FECHA_DEF, SEXO, GRUPO_EDAD, DIABETES, EPOC, ASMA, HIPERTENSION, CARDIOVASCULAR,RENAL_CRONICA, ZONA) %>%
summarise(num_def = n())%>%
rename(fecha = FECHA_DEF,
sexo = SEXO,
diabetes = DIABETES,
epoc = EPOC,
asma = ASMA,
hta = HIPERTENSION,
cardio = CARDIOVASCULAR,
erc = RENAL_CRONICA,
zona = ZONA)
# Separamos variables de parametro
# Union con base de defunciones
regres_zona_2 <- regresion_zona %>%
# spread(., key = parametro, value = value)
pivot_wider(.,names_from = parametro, values_from = value) %>%
left_join(., def_zona_2)
View(regres_zona_2)
# Cargamos base
regres_zona <- fread("Bases/regres_zona.csv",
encoding = "Latin-1")
# Guardamos como csv
write.csv(regres_zona_2, "Bases/regres_zona_2.csv",
row.names = F,
fileEncoding = "ISO-8859-1")
# Cargamos base
regres_zona_2 <- fread("Bases/regres_zona_2.csv",
encoding = "Latin-1")
View(regres_zona_2)
# Cargamos base
regres_zona_2 <- fread("Bases/regres_zona_2.csv",
encoding = "Latin-1") %>%
mutate_all(regres_zona_2, ~replace(., is.na(.), 0))
# Cargamos base
regres_zona_2 <- fread("Bases/regres_zona_2.csv",
encoding = "Latin-1") %>%
mutate_all(regres_zona_2, ~replace(., is.na(.), 0))
regres_zona2 <- mutate_all(regres_zona_2, ~replace(., is.na(.), 0))
regres_zona_2 <- mutate_all(regres_zona_2, ~replace(., is.na(.), 0))
# Cargamos base
regres_zona_2 <- fread("Bases/regres_zona_2.csv",
encoding = "Latin-1")
regres_zona_2 <- mutate_all(regres_zona_2, ~replace(., is.na(.), 0))
View(regres_zona_2)
# 1. Cargamos base
#### Reemplazamos NAs con ceros
#### Filtramos las fechas desde dic de 2019 hasta dic de 2021
regres_zona <- fread("Bases/regres_zona.csv",
encoding = "Latin-1") %>%
mutate_if(., is.numeric, ~replace(., is.na(.), 0)) %>%
filter(fecha >= "2019-12-01" & fecha <= "2021-12-31")
# 1. Cargamos base
#### Reemplazamos NAs con ceros
#### Filtramos las fechas desde dic de 2019 hasta dic de 2021
regres_zona <- fread("Bases/regres_zona.csv",
encoding = "Latin-1") %>%
mutate_if(., is.numeric, ~replace(., is.na(.), 0)) %>%
filter(fecha >= "2020-01-01" & fecha <= "2021-12-31")
# 3. Revisamos la variable de respuesta = num. de defunciones con un histograma
ggplot(regres_zona, aes(num_def)) +
geom_histogram(binwith = 5, position = "dodge") +
xlab("Numero de defunciones por COVID-19") +
theme_bw()
# 1. Cargamos base
#### Reemplazamos NAs con ceros
#### Filtramos las fechas desde dic de 2019 hasta dic de 2021
regres_zona <- fread("Bases/regres_zona.csv",
encoding = "Latin-1") %>%
mutate_if(., is.numeric, ~replace(., is.na(.), 0)) %>%
filter(fecha >= "2020-03-01" & fecha <= "2021-12-31")
# 3. Revisamos la variable de respuesta = num. de defunciones con un histograma
ggplot(regres_zona, aes(num_def)) +
geom_histogram(binwith = 5, position = "dodge") +
xlab("Numero de defunciones por COVID-19") +
theme_bw()
# 1. Cargamos base
#### Reemplazamos NAs con ceros
#### Filtramos las fechas desde dic de 2019 hasta dic de 2021
regres_zona <- fread("Bases/regres_zona.csv",
encoding = "Latin-1") %>%
mutate_if(., is.numeric, ~replace(., is.na(.), 0)) %>%
filter(fecha >= "2020-01-01" & fecha <= "2021-12-31")
# 3. Revisamos la variable de respuesta = num. de defunciones con un histograma
ggplot(regres_zona, aes(num_def)) +
geom_histogram(binwith = 5, position = "dodge") +
xlab("Numero de defunciones por COVID-19") +
theme_bw()
View(regres_zona)
library(dplyr)
library(data.table)
library(GGally)
library(PerformanceAnalytics)
#Correlación individual
regres_zona %>%
mutate(num_def = ifelse(is.na(num_def), 0, num_def)) %>%
filter(zona == "NORESTE") %>%
select("PM2.5", "RH", "TMP", "WSP", "num_def") %>%
mutate(num_def_7d = zoo::rollmean(num_def, k = 7, fill = NA, align = "right"),
PM2.5_7d = zoo::rollmean(PM2.5, k = 7, fill = NA, align = "right"),
RH_7d = zoo::rollmean(RH, k = 7, fill = NA, align = "right"),
TMP_7d = zoo::rollmean(TMP, k = 7, fill = NA, align = "right"),
WSP_7d = zoo::rollmean(WSP, k = 7, fill = NA, align = "right")) %>%
chart.Correlation(., histogram=TRUE, pch=19)
#Multicorrelación
regres_zona %>%
mutate(fecha = as.Date(fecha),
num_def = ifelse(is.na(num_def), 0, num_def)) %>%
#filter(zona == "CENTRO") %>%
select("zona","fecha","PM2.5", "RH", "TMP", "WSP", "num_def") %>%
mutate(num_def_7d = zoo::rollmean(num_def, k = 7, fill = NA, align = "right"),
PM2.5_7d = zoo::rollmean(PM2.5, k = 7, fill = NA, align = "right"),
RH_7d = zoo::rollmean(RH, k = 7, fill = NA, align = "right"),
TMP_7d = zoo::rollmean(TMP, k = 7, fill = NA, align = "right"),
WSP_7d = zoo::rollmean(WSP, k = 7, fill = NA, align = "right")) %>%
filter(fecha >= "2020-03-25") %>%
select(num_def_7d, PM2.5_7d,    RH_7d,   TMP_7d, WSP_7d) %>%
ggpairs(., columns = 2:6, aes(color = zona),
lower = list(continuous = "smooth"))
View(regres_zona)
#Multicorrelación
regres_zona %>%
mutate(fecha = as.Date(fecha),
num_def = ifelse(is.na(num_def), 0, num_def)) %>%
#filter(zona == "CENTRO") %>%
select("zona","fecha","PM2.5", "RH", "TMP", "WSP", "num_def") %>%
mutate(num_def_7d = zoo::rollmean(num_def, k = 7, fill = NA, align = "right"),
PM2.5_7d = zoo::rollmean(PM2.5, k = 7, fill = NA, align = "right"),
RH_7d = zoo::rollmean(RH, k = 7, fill = NA, align = "right"),
TMP_7d = zoo::rollmean(TMP, k = 7, fill = NA, align = "right"),
WSP_7d = zoo::rollmean(WSP, k = 7, fill = NA, align = "right")) %>%
filter(fecha >= "2020-03-25") %>%
select(num_def_7d, PM2.5_7d,    RH_7d,   TMP_7d, WSP_7d) %>%
ggpairs(., columns = 2:6, aes(color = zona),
lower = list(continuous = "smooth"))
cor(x = regres_zona$num_def, y = regres_zona$PM2.5, method = "spearman")
with(regres_zona, plot(x= num_def, y= PM2.5, pch=20, col='blue',
xlab='Defunciones por COVID-19', las=1,
ylab='Concentraciones de PM2.5'))
cor(x = regres_zona$PM2.5, y = regres_zona$num_def, method = "spearman")
cor(x = regres_zona$PM2.5, y = regres_zona$num_def, method = "pearson")
View(regres_zona)
regres_zona <- fread("Bases/regres_zona.csv",
encoding = "Latin-1")
#Correlación individual
regres_zona %>%
mutate(num_def = ifelse(is.na(num_def), 0, num_def)) %>%
filter(zona == "NORESTE") %>%
select("PM2.5", "RH", "TMP", "WSP", "num_def") %>%
mutate(num_def_7d = zoo::rollmean(num_def, k = 7, fill = NA, align = "right"),
PM2.5_7d = zoo::rollmean(PM2.5, k = 7, fill = NA, align = "right"),
RH_7d = zoo::rollmean(RH, k = 7, fill = NA, align = "right"),
TMP_7d = zoo::rollmean(TMP, k = 7, fill = NA, align = "right"),
WSP_7d = zoo::rollmean(WSP, k = 7, fill = NA, align = "right")) %>%
chart.Correlation(., histogram=TRUE, pch=19)
#Multicorrelación
regres_zona %>%
mutate(fecha = as.Date(fecha),
num_def = ifelse(is.na(num_def), 0, num_def)) %>%
#filter(zona == "CENTRO") %>%
select("zona","fecha","PM2.5", "RH", "TMP", "WSP", "num_def") %>%
mutate(num_def_7d = zoo::rollmean(num_def, k = 7, fill = NA, align = "right"),
PM2.5_7d = zoo::rollmean(PM2.5, k = 7, fill = NA, align = "right"),
RH_7d = zoo::rollmean(RH, k = 7, fill = NA, align = "right"),
TMP_7d = zoo::rollmean(TMP, k = 7, fill = NA, align = "right"),
WSP_7d = zoo::rollmean(WSP, k = 7, fill = NA, align = "right")) %>%
filter(fecha >= "2020-03-25") %>%
select(zona, num_def_7d, PM2.5_7d,    RH_7d,   TMP_7d, WSP_7d) %>%
ggpairs(., columns = 2:6, aes(color = zona),
lower = list(continuous = "smooth"))
cor(x = regres_zona$PM2.5, y = regres_zona$num_def, method = "spearman")
cor(x = regres_zona$num_def, y = regres_zona$PM2.5, method = "spearman")
View(regres_zona)
regres_zona <- fread("Bases/regres_zona.csv",
encoding = "Latin-1") %>%
mutate_if(., is.numeric, ~replace(., is.na(.), 0))
cor(x = regres_zona$num_def, y = regres_zona$PM2.5, method = "spearman")
with(regres_zona, plot(x= num_def, y= PM2.5, pch=20, col='blue',
xlab='Defunciones por COVID-19', las=1,
ylab='Concentraciones de PM2.5'))
regres_zona_NE <- regres_zona %>%
filter(zona == "NORESTE")
cor(x = regres_zona_NE$num_def, y = regres_zona_NE$PM2.5, method = "spearman")
library(astsa)
library(tseries)
## Cargamos base de pm2.5
pm <- fread("Bases/pm.csv",
encoding = "Latin-1") %>%
filter(!is.na(zona))
# Creamos data frame para serie de tiempo
pm.st <- pm_st[,-1]
## Creamos la variable semanaepi empezando por domingo
## Cambiamos semanaepi a formato de fecha
## Agrupamos por semana epi y fecha
## Sacamos promedios por dia
pm_st <- pm %>%
mutate(semanaepi = yearweek(fecha, week_start = 7)) %>%
group_by(semanaepi) %>%
summarise(value = mean(value))
pacman::p_load(rio,          # File import
here,         # File locator
tidyverse,    # data management + ggplot2 graphics
tsibble,      # handle time series datasets
slider,       # for calculating moving averages
imputeTS,     # for filling in missing values
feasts,       # for time series decomposition and autocorrelation
forecast,     # fit sin and cosin terms to data (note: must load after feasts)
trending,     # fit and assess models
tmaptools,    # for getting geocoordinates (lon/lat) based on place names
ecmwfr,       # for interacting with copernicus sateliate CDS API
stars,        # for reading in .nc (climate data) files
units,        # for defining units of measurement (climate data)
yardstick,    # for looking at model accuracy
surveillance  # for aberration detection
)
library(vctrs)
library(slider)
# Creamos data frame para serie de tiempo
pm.st <- pm_st[,-1]
## Creamos la variable semanaepi empezando por domingo
## Cambiamos semanaepi a formato de fecha
## Agrupamos por semana epi y fecha
## Sacamos promedios por dia
pm_st <- pm %>%
mutate(semanaepi = yearweek(fecha, week_start = 7)) %>%
group_by(semanaepi) %>%
summarise(value = mean(value))
# 1. Cargamos base
#### Reemplazamos NAs con ceros
#### Filtramos las fechas desde dic de 2019 hasta dic de 2021
regres_zona <- fread("Bases/regres_zona.csv",
encoding = "Latin-1") %>%
mutate_if(., is.numeric, ~replace(., is.na(.), 0)) %>%
filter(fecha >= "2020-01-01" & fecha <= "2021-12-31")
# 1. Cargamos base
#### Reemplazamos NAs con ceros
#### Filtramos las fechas desde dic de 2019 hasta dic de 2021
regres_zona <- fread("Bases/regres_zona.csv",
encoding = "Latin-1") %>%
mutate_if(., is.numeric, ~replace(., is.na(.), 0)) %>%
filter(fecha >= "2020-03-01" & fecha <= "2021-12-31")
View(regres_zona)
# 3. Revisamos la variable de respuesta = num. de defunciones con un histograma
ggplot(regres_zona, aes(num_def)) +
geom_histogram(binwith = 5, position = "dodge") +
xlab("Numero de defunciones por COVID-19") +
theme_bw()
# 1. Cargamos base
#### Reemplazamos NAs con ceros
#### Filtramos las fechas desde dic de 2019 hasta dic de 2021
regres_zona <- fread("Bases/regres_zona.csv",
encoding = "Latin-1") %>%
mutate_if(., is.numeric, ~replace(., is.na(.), 0)) %>%
filter(fecha >= "2020-03-01" & fecha <= "2021-12-31",
zona == "NORESTE")
# 3. Revisamos la variable de respuesta = num. de defunciones con un histograma
ggplot(regres_zona, aes(num_def)) +
geom_histogram(binwith = 5, position = "dodge") +
xlab("Numero de defunciones por COVID-19") +
theme_bw()
# 2. Revisamos si hay sobredispersion de los datos con la prueba de Cameron y Trivedi
#### Cargamos libreria overdisp
library(overdisp)
overdisp(regres_zona, dependent.position = 7, predictor.position = 2:6)
View(regres_zona)
overdisp(regres_zona, dependent.position = 7, predictor.position = 2:6)
regres_zona <- fread("Bases/regres_zona.csv",
encoding = "Latin-1") %>%
mutate_if(., is.numeric, ~replace(., is.na(.), 0)) %>%
filter(fecha >= "2020-03-01" & fecha <= "2021-12-31")
overdisp(regres_zona, dependent.position = 7, predictor.position = 2:6)
# 1. Cargamos base
#### Reemplazamos NAs con ceros
#### Filtramos las fechas desde dic de 2019 hasta dic de 2021
regres_zona <- fread("Bases/regres_zona.csv",
encoding = "Latin-1") %>%
mutate_if(., is.numeric, ~replace(., is.na(.), 0)) %>%
filter(fecha >= "2020-03-01" & fecha <= "2021-12-31",
zona == "NORESTE")
View(regres_zona)
overdisp(regres_zona, dependent.position = 7, predictor.position = 3:6)
regres_zona <- fread("Bases/regres_zona.csv",
encoding = "Latin-1")
View(regres_zona)
sum(is.na(regres_zona$PM2.5))
# Creamos data frame para serie de tiempo
pm.st <- pm_st[,-1]
# Conciertimos en objeto de serie de tiempo y
# Le asignamos las fechas de inicio y final, por semana (por eso 52)
pm.ts = ts(pm.st, start = c(2019,1), end = c(2021,52), frequency = 52)
# La abrimos
pm.ts
View(pm.st)
plot(pm.ts)
# Creamos boxplot de la serie de tiempo
boxplot(pm.ts~cycle(pm.ts))
# Para modelo aditivo = varianza constante
modeloaditivo = decompose(pm.ts)
plot(modeloaditivo)
# Para modelo multiplicativo = varianza incrementa
modelomultiplicativo = decompose(pm.ts, type = "mult")
plot(modelomultiplicativo)
#Para estimar la tendencia
Tendencia = modelomultiplicativo$trend
print(Tendencia)
#Para estimar la Estacionalidad
Estacionalidad = modelomultiplicativo$seasonal
print(Estacionalidad)
ts.plot(cbind(Tendencia, Tendencia*Estacionalidad), lty = 1:2)
# La convertimos en logaritmo para convertirla en estacionaria
serielog =log(pm.ts)
serielog
plot(serielog)
adf.test(serielog, alternative = "stationary")
# Como no funcionó calculamos las diferencias para convertirla en estacionaria
seriedif = diff(pm.ts)
seriedif
plot(seriedif)
adf.test(seriedif, alternative = "stationary")
# Cargamos librerias
library(data.table)
library(tidyverse)
library(raster)
library(stringi)
library(leaflet)
library(aweek)
# Cargamos base de mortalidad por municipio filtrada para 2020
mort_mun <- fread("Bases/mort_mun.csv",
encoding = "Latin-1") %>%
filter(AÑO ==  2020)
# Cargamos base de pm
pm <- fread("Bases/pm.csv",
encoding = "Latin-1")
# Cargamos base de pm
# Eliminamos valores nulos de zona (municipios que no pertenecen a ZMVM)
pm <- fread("Bases/pm.csv",
encoding = "Latin-1") %>%
filter(!is.na(zona))
# Cargamos base
regres_zona <- fread("Bases/regres_zona.csv",
encoding = "Latin-1")
View(regres_zona)
View(pm)
View(regres_zona)
